#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import feedparser
import time
import os
import sqlite3
import re
from datetime import datetime, timedelta
from email.utils import parsedate_to_datetime

HF_TOKEN = os.getenv("HF_API_TOKEN")
TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

RSS_URL = "https://lenta.ru/rss"
DB = "data/sent_links.db"

def safe_log(msg):
    print(f"[{time.strftime('%H:%M:%S')}] {msg}")

def init_db():
    os.makedirs("data", exist_ok=True)
    conn = sqlite3.connect(DB)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS sent (
            url TEXT PRIMARY KEY,
            title TEXT,
            summary TEXT,
            time TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()

def was_sent(url):
    conn = sqlite3.connect(DB)
    result = conn.execute("SELECT 1 FROM sent WHERE url=?", (url,)).fetchone()
    conn.close()
    return result is not None

def mark_sent(url, title, summary):
    conn = sqlite3.connect(DB)
    conn.execute(
        "INSERT OR IGNORE INTO sent VALUES (?, ?, ?, ?)",
        (url, title, summary, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    )
    conn.commit()
    conn.close()

# ---------- –í–†–ï–ú–Ø –ò –§–ò–õ–¨–¢–† –ó–ê –ü–û–°–õ–ï–î–ù–ò–ô –ß–ê–° ----------

def parse_rss_time(time_str):
    """
    pubDate –≤ RSS: 'Tue, 18 Nov 2025 19:18:00 +0300'
    –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ datetime –≤ –ú–°–ö (–±–µ–∑ tzinfo), —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å now (—Ç–æ–∂–µ –ú–°–ö).
    """
    try:
        dt = parsedate_to_datetime(time_str)  # aware datetime
        # GitHub runner –≤ UTC, –Ω–æ Lenta –¥–∞—ë—Ç +0300 (MSK),
        # –Ω–∞–º —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –ú–°–ö –±–µ–∑ tzinfo:
        dt = dt.astimezone().astimezone()  # –ø—Ä–æ—Å—Ç–æ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ aware
        # –û—Å—Ç–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è, –Ω–æ –±–µ–∑ tzinfo (–∫–∞–∫ "–Ω–∞ —Å—Ç–µ–Ω–µ —á–∞—Å–æ–≤"):
        dt = dt.replace(tzinfo=None)
        return dt
    except Exception:
        return None

def is_within_last_hour(article_time):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–æ–≤–æ—Å—Ç—å –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª [now-1h, now).
    –†–∞–±–æ—Ç–∞–µ—Ç –≤ "–ª–æ–∫–∞–ª—å–Ω–æ–º" –≤—Ä–µ–º–µ–Ω–∏ (–∫–∞–∫ –≤–∏–¥–∏—Ç GitHub + –Ω–∞—à dt –±–µ–∑ tzinfo).
    """
    if not article_time:
        # –ï—Å–ª–∏ –≤—Ä–µ–º—è –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏ ‚Äî –Ω–µ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º, –ª—É—á—à–µ –æ—Ç–¥–∞—Ç—å –Ω–∞ –ò–ò
        return True

    now = datetime.now()
    one_hour_ago = now - timedelta(hours=1)
    return one_hour_ago <= article_time < now

def fetch_lenta_last_hour():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ RSS –∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ,
    —á—Ç–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å.
    """
    safe_log("üì∞ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å...")
    feed = feedparser.parse(RSS_URL)
    articles = []

    for entry in feed.entries[:100]:
        title = (entry.get("title") or "").strip()
        link = (entry.get("link") or "").strip()
        desc = (entry.get("summary") or "")[:400].strip()

        # –í—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        published = entry.get("published") or entry.get("pubDate") or ""
        article_time = parse_rss_time(published)

        if not is_within_last_hour(article_time):
            continue

        # –ß–∏—Å—Ç–∏–º –æ—Ç —Ü–∏—Ñ—Ä –≤ –∫–æ–Ω—Ü–µ
        title = re.sub(r'\d+$', '', title).strip()
        desc = re.sub(r'\d+$', '', desc).strip()

        # –ö–∞—Ä—Ç–∏–Ω–∫–∞
        image_url = None
        if hasattr(entry, 'media_content') and entry.media_content:
            image_url = entry.media_content[0].get('url')
        if not image_url and hasattr(entry, 'enclosures') and entry.enclosures:
            image_url = entry.enclosures[0].get('href')

        if not title or not link or len(desc) < 30:
            continue

        if was_sent(link):
            continue

        articles.append({
            "title": title,
            "desc": desc,
            "url": link,
            "image": image_url,
            "time": article_time
        })

    safe_log(f"‚úì –ù–∞–π–¥–µ–Ω–æ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å: {len(articles)}")
    return articles

# ---------- QWEN: –†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï ----------

def rank_articles_with_ai(articles):
    """
    Qwen –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø 3-5 –Ω–æ–≤–æ—Å—Ç–µ–π.
    –ï—Å–ª–∏ HF_TOKEN –Ω–µ—Ç –∏–ª–∏ —á—Ç–æ-—Ç–æ –ø–∞–¥–∞–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ –¥–æ 5.
    """
    if not articles or not HF_TOKEN:
        return articles[:5]

    if len(articles) <= 5:
        return articles

    safe_log(f"ü§ñ –ò–ò —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π...")

    # –ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º –ø–µ—Ä–≤—ã–µ 20 –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    subset = articles[:20]
    items_text = "\n".join(
        f"{i+1}. [{a['title']}] {a['desc'][:120]}"
        for i, a in enumerate(subset)
    )

    prompt = f"""–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞.
–ò–∑ —Å–ø–∏—Å–∫–∞ –Ω–∏–∂–µ –≤—ã–±–µ—Ä–∏ 3-5 –°–ê–ú–´–• –í–ê–ñ–ù–´–• –Ω–æ–≤–æ—Å—Ç–µ–π.

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏:
- –í–ª–∏—è–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π
- –ü–æ–ª–∏—Ç–∏–∫–∞, —ç–∫–æ–Ω–æ–º–∏–∫–∞, –≤–æ–π–Ω—ã, –ß–ü, –≥—Ä–æ–º–∫–∏–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- –í—ã—Å–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–µ—Å –∞—É–¥–∏—Ç–æ—Ä–∏–∏

–°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π:
{items_text}

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –ù–û–ú–ï–†–ê–ú–ò —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1,3,5,7)."""

    try:
        response = requests.post(
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
            headers={"Authorization": f"Bearer {HF_TOKEN}"},
            json={
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 50,
                    "temperature": 0.3,
                    "do_sample": False
                }
            },
            timeout=25
        )

        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and data:
                text = data[0].get("generated_text", "").strip()
                # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –æ—Ç–≤–µ—Ç
                line = text.split("\n")[-1]
                nums = []
                for part in line.replace(" ", "").split(","):
                    if part.isdigit():
                        idx = int(part) - 1
                        if 0 <= idx < len(subset):
                            nums.append(idx)
                nums = list(dict.fromkeys(nums))  # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                if nums:
                    chosen = [subset[i] for i in nums]
                    safe_log(f"‚úì –ò–ò –≤—ã–±—Ä–∞–ª –Ω–æ–≤–æ—Å—Ç–∏: {[i+1 for i in nums]}")
                    return chosen

    except Exception as e:
        safe_log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)[:80]}")

    # Fallback
    return articles[:5]

# ---------- QWEN: –ü–ï–†–ï–ü–ò–°–¨ –ù–û–í–û–°–¢–ò ----------

def rewrite_with_hf(title, text):
    """
    Qwen –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –≤ 2‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    """
    if not HF_TOKEN:
        return text[:180]

    prompt = f"""–ü–µ—Ä–µ–ø–∏—à–∏ –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –≤ 2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
–°–¥–µ–ª–∞–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∂–∏–≤–æ–π –∏ –ø–æ–Ω—è—Ç–Ω–æ–π, –ù–ï –∫–æ–ø–∏—Ä—É–π –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ—Å–ª–æ–≤–Ω–æ.

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–¢–µ–∫—Å—Ç: {text}

–û—Ç–≤–µ—Ç: —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ –±–µ–∑ –ª–∏—à–Ω–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""

    try:
        response = requests.post(
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
            headers={"Authorization": f"Bearer {HF_TOKEN}"},
            json={
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 120,
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "do_sample": True
                }
            },
            timeout=25
        )

        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and data:
                result = data[0].get("generated_text", "").strip()
                # –û—Ç—Ä–µ–∑–∞–µ–º –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –µ–≥–æ –ø–æ–≤—Ç–æ—Ä–∏–ª–∞
                if prompt in result:
                    result = result.split(prompt)[-1].strip()
                # –ë–µ—Ä—ë–º 2‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                sentences = [s.strip() for s in result.split(".") if s.strip()]
                result = ". ".join(sentences[:3]) + "."
                result = re.sub(r'\d+$', '', result).strip()
                if len(result) > 30:
                    return result[:400]
    except Exception as e:
        safe_log(f"‚ö†Ô∏è HF –æ—à–∏–±–∫–∞: {str(e)[:80]}")

    return text[:180]

# ---------- –ö–ê–†–¢–ò–ù–ö–ê ----------

def download_image(url):
    if not url:
        return None
    try:
        r = requests.get(url, timeout=7)
        if r.status_code == 200:
            os.makedirs("data", exist_ok=True)
            path = os.path.join("data", f"img_{int(time.time())}.jpg")
            with open(path, "wb") as f:
                f.write(r.content)
            return path
    except:
        pass
    return None

# ---------- –û–¢–ü–†–ê–í–ö–ê –í TELEGRAM ----------

def send_to_telegram(articles):
    if not articles:
        safe_log("‚ö†Ô∏è –ù–ï–¢ –ù–û–í–û–°–¢–ï–ô –î–õ–Ø –ü–£–ë–õ–ò–ö–ê–¶–ò–ò")
        return 0

    safe_log(f"üì§ –ü—É–±–ª–∏–∫—É—é {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π...\n")
    sent = 0

    for i, art in enumerate(articles, 1):
        title = art["title"]
        summary = rewrite_with_hf(title, art["desc"])

        msg = f"*{title}*\n\n{summary}"
        image_path = download_image(art.get("image"))

        try:
            if image_path and os.path.exists(image_path):
                with open(image_path, "rb") as photo:
                    files = {"photo": photo}
                    data = {
                        "chat_id": TG_CHAT_ID,
                        "caption": msg,
                        "parse_mode": "Markdown"
                    }
                    requests.post(
                        f"https://api.telegram.org/bot{TG_TOKEN}/sendPhoto",
                        files=files,
                        data=data,
                        timeout=15
                    )
                try:
                    os.remove(image_path)
                except:
                    pass
            else:
                requests.post(
                    f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage",
                    json={
                        "chat_id": TG_CHAT_ID,
                        "text": msg,
                        "parse_mode": "Markdown"
                    },
                    timeout=15
                )

            safe_log(f"‚úì [{i}] {title[:50]}...")
            mark_sent(art["url"], art["title"], summary)
            sent += 1

            if i < len(articles):
                # –î–ª—è GitHub Actions –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å 10‚Äì30 —Å–µ–∫—É–Ω–¥,
                # –Ω–∞ VPS –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å 300‚Äì600 (5‚Äì10 –º–∏–Ω—É—Ç)
                time.sleep(10)

        except Exception as e:
            safe_log(f"‚úó [{i}] –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {str(e)[:80]}")

    return sent

# ---------- MAIN ----------

def main():
    safe_log("üöÄ LENTA ‚Üí TELEGRAM (QWEN, LAST HOUR)")
    safe_log("‚è∞ –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å...\n")

    if not all([HF_TOKEN, TG_TOKEN, TG_CHAT_ID]):
        safe_log("‚ùå –ù–ï–¢ –°–ï–ö–†–ï–¢–û–í HF_API_TOKEN / TG_TOKEN / TG_CHAT_ID")
        return

    init_db()
    articles = fetch_lenta_last_hour()

    if not articles:
        safe_log("‚ÑπÔ∏è –ù–ï–¢ –ù–û–í–û–°–¢–ï–ô –ó–ê –ü–û–°–õ–ï–î–ù–ò–ô –ß–ê–°")
        return

    top_articles = rank_articles_with_ai(articles)
    sent = send_to_telegram(top_articles)
    safe_log(f"\n‚ú® –ì–û–¢–û–í–û! –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {sent}/{len(top_articles)}")

if __name__ == "__main__":
    main()
