#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
import feedparser
from datetime import datetime
from openai import OpenAI
import time
import os
import sqlite3

# ============= –ö–û–ù–§–ò–ì =============
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")
GNEWS_KEY = os.getenv("GNEWS_KEY")
PERPLEXITY_KEY = os.getenv("PERPLEXITY_KEY")
TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

USE_PERPLEXITY_SUMMARY = True
INTERVAL_BETWEEN_POSTS = 30
ARTICLES_TO_SEND = 50
DB = "data/sent_links.db"

# ============= PERPLEXITY =============

def create_perplexity_client():
    return OpenAI(
        api_key=PERPLEXITY_KEY,
        base_url="https://api.perplexity.ai"
    )

# ============= –õ–û–ì–ò–†–û–í–ê–ù–ò–ï =============

def safe_log(msg):
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {msg}")

def log_section(title):
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}\n")

# ============= –ë–î =============

def init_db():
    os.makedirs("data", exist_ok=True)
    conn = sqlite3.connect(DB)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS sent (
            url TEXT PRIMARY KEY,
            title TEXT,
            time TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()

def was_sent(url):
    conn = sqlite3.connect(DB)
    result = conn.execute("SELECT 1 FROM sent WHERE url=?", (url,)).fetchone()
    conn.close()
    return result is not None

def mark_sent(url, title):
    conn = sqlite3.connect(DB)
    conn.execute("INSERT OR IGNORE INTO sent VALUES (?, ?, ?)", 
                 (url, title, datetime.now()))
    conn.commit()
    conn.close()

# ============= NEWSAPI =============

def fetch_newsapi(articles_list):
    categories = ["business", "technology", "science", "health", "entertainment", "general"]
    safe_log("üì∞ NewsAPI...")
    
    for category in categories:
        try:
            url = "https://newsapi.org/v2/top-headlines"
            params = {
                "country": "ru",
                "category": category,
                "apiKey": NEWSAPI_KEY,
                "sortBy": "publishedAt",
                "pageSize": 8
            }
            r = requests.get(url, params=params, timeout=10)
            data = r.json()
            if data.get("status") == "ok":
                for article in data.get("articles", []):
                    if article.get("title") and article.get("url") and not was_sent(article.get("url")):
                        articles_list.append({
                            "title": article.get("title"),
                            "description": article.get("description"),
                            "url": article.get("url"),
                            "source": f"NewsAPI ({category})",
                        })
                safe_log(f"  ‚úì {category}: +{len(data.get('articles', []))}")
            time.sleep(1)
        except Exception as e:
            safe_log(f"  ‚úó {category}: {e}")
    
    return articles_list

# ============= GNEWS =============

def fetch_gnews(articles_list):
    queries = ["–Ω–æ–≤–æ—Å—Ç–∏", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è", "–±–∏–∑–Ω–µ—Å", "—Å–ø–æ—Ä—Ç", "–Ω–∞—É–∫–∞", "–∑–¥–æ—Ä–æ–≤—å–µ"]
    safe_log("üîç GNews...")
    
    for query in queries:
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": query,
                "country": "ru",
                "apikey": GNEWS_KEY,
                "max": 6,
                "lang": "ru",
                "sortby": "publishedAt"
            }
            r = requests.get(url, params=params, timeout=10)
            data = r.json()
            if data.get("articles"):
                for article in data.get("articles", []):
                    if article.get("title") and article.get("url") and not was_sent(article.get("url")):
                        articles_list.append({
                            "title": article.get("title"),
                            "description": article.get("description"),
                            "url": article.get("url"),
                            "source": f"GNews ({query})",
                        })
                safe_log(f"  ‚úì {query}: +{len(data.get('articles', []))}")
            time.sleep(1)
        except Exception as e:
            safe_log(f"  ‚úó {query}: {e}")
    
    return articles_list

# ============= RSS =============

def fetch_rss(articles_list):
    rss_feeds = [
        ("Lenta.ru", "https://lenta.ru/rss"),
        ("RBC", "https://rbc.ru/rbc/news/rssfull"),
        ("BBC Russian", "https://www.bbc.com/russian/index.xml"),
        ("Interfax", "https://rss.interfax.ru/politics/"),
        ("Meduza", "https://meduza.io/rss/all"),
        ("TASS", "https://tass.ru/rss/v2.xml"),
        ("Kommersant", "https://www.kommersant.ru/RSS/news.xml"),
    ]
    
    safe_log("üåê RSS...")
    
    for source_name, feed_url in rss_feeds:
        try:
            feed = feedparser.parse(feed_url)
            for entry in feed.entries[:3]:
                title = entry.get("title", "")
                link = entry.get("link", "")
                summary = entry.get("summary", "")[:300]
                
                if title and link and not was_sent(link):
                    articles_list.append({
                        "title": title,
                        "description": summary,
                        "url": link,
                        "source": f"RSS ({source_name})",
                    })
            safe_log(f"  ‚úì {source_name}: +{min(len(feed.entries), 3)}")
        except Exception as e:
            safe_log(f"  ‚úó {source_name}: {e}")
    
    return articles_list

# ============= –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø =============

def deduplicate_articles(articles):
    safe_log(f"üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
    
    seen = set()
    unique = []
    
    for article in articles:
        url = article.get("url", "")
        if url and url not in seen:
            seen.add(url)
            unique.append(article)
    
    safe_log(f"   ‚Üí {len(unique)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")
    return unique

# ============= AI –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø =============

def summarize_with_perplexity(articles, limit=None):
    if limit:
        articles = articles[:limit]
    
    safe_log(f"ü§ñ Perplexity: {len(articles)}...\n")
    
    client = create_perplexity_client()
    summarized = []
    
    for i, article in enumerate(articles, 1):
        title = article.get("title", "")
        desc = article.get("description", "")
        
        if not title or not desc:
            article["summary"] = desc if desc else title
            summarized.append(article)
            continue
        
        prompt = f"""–ù–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è Telegram:

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–û–ø–∏—Å–∞–Ω–∏–µ: {desc}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ú–∞–∫—Å–∏–º—É–º 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- –î–æ–±–∞–≤—å 1-2 —ç–º–æ–¥–∑–∏
- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
- –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º"""
        
        try:
            response = client.chat.completions.create(
                model="sonar",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.7
            )
            
            article["summary"] = response.choices[0].message.content
            safe_log(f"  [{i}/{len(articles)}] ‚úì {title[:40]}...")
            
        except Exception as e:
            safe_log(f"  [{i}/{len(articles)}] ‚úó {e}")
            article["summary"] = desc[:150] if desc else title
        
        summarized.append(article)
        time.sleep(0.2)
    
    return summarized

# ============= TELEGRAM =============

def send_to_telegram(articles, limit=None):
    if limit:
        articles = articles[:limit]
    
    log_section(f"üì§ –û–¢–ü–†–ê–í–ö–ê {len(articles)} –ü–û–°–¢–û–í")
    
    telegram_url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    
    sent = 0
    failed = 0
    
    for i, article in enumerate(articles, 1):
        title = article.get("title", "")[:50]
        summary = article.get("summary", article.get("description", ""))[:500]
        url = article.get("url", "")
        source = article.get("source", "–ò—Å—Ç–æ—á–Ω–∏–∫")
        
        if not url:
            continue
        
        message = f"""*{title}*

{summary}

üîó [{source}]({url})"""
        
        try:
            response = requests.post(
                telegram_url,
                json={
                    "chat_id": TG_CHAT_ID,
                    "text": message,
                    "parse_mode": "Markdown",
                    "disable_web_page_preview": False
                },
                timeout=10
            )
            
            if response.status_code == 200:
                safe_log(f"[{i}/{len(articles)}] ‚úì {title}...")
                mark_sent(url, title)
                sent += 1
            else:
                safe_log(f"[{i}/{len(articles)}] ‚úó HTTP {response.status_code}")
                failed += 1
        
        except Exception as e:
            safe_log(f"[{i}/{len(articles)}] ‚úó {e}")
            failed += 1
        
        if i < len(articles):
            time.sleep(INTERVAL_BETWEEN_POSTS)
    
    log_section("‚ú® –†–ï–ó–£–õ–¨–¢–ê–¢")
    safe_log(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {sent}")
    if failed > 0:
        safe_log(f"‚ùå –û—à–∏–±–æ–∫: {failed}")
    
    return sent, failed

# ============= MAIN =============

def main():
    log_section("üöÄ TELEGRAM NEWS BOT")
    
    keys = {
        "NEWSAPI_KEY": NEWSAPI_KEY,
        "GNEWS_KEY": GNEWS_KEY,
        "PERPLEXITY_KEY": PERPLEXITY_KEY,
        "TG_TOKEN": TG_TOKEN,
        "TG_CHAT_ID": TG_CHAT_ID
    }
    
    for key_name, key_value in keys.items():
        if not key_value:
            safe_log(f"‚ùå –û–®–ò–ë–ö–ê: {key_name} –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            return
    
    safe_log("‚úì –í—Å–µ –∫–ª—é—á–∏ –≥–æ—Ç–æ–≤—ã")
    
    init_db()
    
    log_section("–≠–¢–ê–ü 1: –°–ë–û–†")
    articles = []
    articles = fetch_newsapi(articles)
    articles = fetch_gnews(articles)
    articles = fetch_rss(articles)
    articles = deduplicate_articles(articles)
    
    if not articles:
        safe_log("‚ùå –ù–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return
    
    safe_log(f"‚úì –°–æ–±—Ä–∞–Ω–æ: {len(articles)}")
    
    log_section("–≠–¢–ê–ü 2: –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø")
    articles = summarize_with_perplexity(articles, limit=ARTICLES_TO_SEND)
    
    log_section("–≠–¢–ê–ü 3: –û–¢–ü–†–ê–í–ö–ê")
    sent, failed = send_to_telegram(articles, limit=ARTICLES_TO_SEND)
    
    log_section("‚ú® –ì–û–¢–û–í–û")
    safe_log(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent} –ø–æ—Å—Ç–æ–≤")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        safe_log(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
