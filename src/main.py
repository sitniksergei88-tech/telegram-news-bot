#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import feedparser
import time
import os
import sqlite3
import re
from datetime import datetime, timedelta
import random

HF_TOKEN = os.getenv("HF_API_TOKEN")
TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

RSS_URL = "https://lenta.ru/rss"
DB = "data/sent_links.db"

def safe_log(msg):
    print(f"[{time.strftime('%H:%M:%S')}] {msg}")

def init_db():
    os.makedirs("data", exist_ok=True)
    conn = sqlite3.connect(DB)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS sent (
            url TEXT PRIMARY KEY, title TEXT, summary TEXT, time TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()

def was_sent(url):
    conn = sqlite3.connect(DB)
    result = conn.execute("SELECT 1 FROM sent WHERE url=?", (url,)).fetchone()
    conn.close()
    return result is not None

def mark_sent(url, title, summary):
    conn = sqlite3.connect(DB)
    conn.execute("INSERT OR IGNORE INTO sent VALUES (?, ?, ?, ?)", 
                 (url, title, summary, time.strftime('%Y-%m-%d %H:%M:%S')))
    conn.commit()
    conn.close()

def parse_rss_time(time_str):
    """–ü–∞—Ä—Å–∏—Ç –≤—Ä–µ–º—è –∏–∑ RSS (RFC 2822)"""
    try:
        from email.utils import parsedate_to_datetime
        dt = parsedate_to_datetime(time_str)
        return dt.replace(tzinfo=None)
    except:
        return None

def is_within_last_hour(article_time):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª–∞ –ª–∏ –Ω–æ–≤–æ—Å—Ç—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å"""
    if not article_time:
        return True
    
    now = datetime.now()
    one_hour_ago = now - timedelta(hours=1)
    
    return one_hour_ago <= article_time <= now

def fetch_lenta_last_hour():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¢–û–õ–¨–ö–û –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å"""
    safe_log("üì∞ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å...")
    feed = feedparser.parse(RSS_URL)
    articles = []
    
    for entry in feed.entries[:100]:
        title = entry.get("title", "").strip()
        link = entry.get("link", "").strip()
        desc = entry.get("summary", "")[:400].strip()
        
        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        published = entry.get("published", "")
        article_time = parse_rss_time(published)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–æ–≤–æ—Å—Ç—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        if not is_within_last_hour(article_time):
            continue
        
        title = re.sub(r'\d+$', '', title).strip()
        desc = re.sub(r'\d+$', '', desc).strip()
        
        image_url = None
        if hasattr(entry, 'media_content') and entry.media_content:
            image_url = entry.media_content[0].get('url')
        
        if not image_url and hasattr(entry, 'enclosures') and entry.enclosures:
            image_url = entry.enclosures[0].get('href')
        
        if not title or not link or len(desc) < 30:
            continue
        
        if was_sent(link):
            continue
        
        articles.append({
            "title": title,
            "desc": desc,
            "url": link,
            "image": image_url,
            "time": article_time
        })
    
    safe_log(f"‚úì –ù–∞–π–¥–µ–Ω–æ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å: {len(articles)}")
    return articles

def rank_articles_with_ai(articles):
    """–ò–ò —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø 1-5"""
    if not articles or not HF_TOKEN:
        return articles[:5]
    
    if len(articles) <= 5:
        return articles
    
    safe_log(f"ü§ñ –ò–ò —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ò–ò
    articles_text = "\n".join([f"{i+1}. [{a['title']}] {a['desc'][:100]}" for i, a in enumerate(articles[:20])])
    
    prompt = f"""–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞. –í—ã–±–µ—Ä–∏ —Å–∞–º—ã–µ –í–ê–ñ–ù–´–ï –∏ –ò–ù–¢–ï–†–ï–°–ù–´–ï –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.

–ö—Ä–∏—Ç–µ—Ä–∏–∏:
- –ë–æ–ª—å—à–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –æ–±—â–µ—Å—Ç–≤–æ
- –ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞ –¥–ª—è —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏
- –ê–∫—Ç—É–∞–ª—å–Ω–∞ –∏ –≤–∞–∂–Ω–∞
- –ù–ï –ø–æ–≤—Ç–æ—Ä—è—é—â–∞—è—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

–°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π:
{articles_text}

–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä–∞ —Ç–æ–ø 3-5 —Å–∞–º—ã—Ö –ª—É—á—à–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ß–ï–†–ï–ó –ó–ê–ü–Ø–¢–£–Æ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1,3,5,7).
–û—Ç–≤–µ—Ç - –¢–û–õ–¨–ö–û –ù–û–ú–ï–†–ê!"""
    
    try:
        response = requests.post(
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
            headers={"Authorization": f"Bearer {HF_TOKEN}"},
            json={
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 50,
                    "temperature": 0.5,
                    "do_sample": False
                }
            },
            timeout=25
        )
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                result = data[0].get("generated_text", "").strip()
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞
                numbers_str = result.split('\n')[-1].strip()
                numbers = [int(n.strip())-1 for n in numbers_str.split(',') if n.strip().isdigit()]
                numbers = [n for n in numbers if 0 <= n < len(articles)]
                
                if numbers:
                    selected = [articles[i] for i in numbers]
                    safe_log(f"‚úì –ò–ò –≤—ã–±—Ä–∞–ª –Ω–æ–≤–æ—Å—Ç–∏: {[i+1 for i in numbers]}")
                    return selected
    except Exception as e:
        safe_log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)[:40]}")
    
    # Fallback: –µ—Å–ª–∏ –ò–ò –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5
    return articles[:5]

def rewrite_with_hf(title, text):
    """–ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å HuggingFace Qwen2.5-7B"""
    if not HF_TOKEN:
        return text[:150]
    
    prompt = f"""–ü–µ—Ä–µ–ø–∏—Å–∏ —ç—Ç—É –Ω–æ–≤–æ—Å—Ç—å –≤ 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ù–µ –∫–æ–ø–∏—Ä—É–π –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å–¥–µ–ª–∞–π —Å–≤–æ—é –≤–µ—Ä—Å–∏—é!

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–¢–µ–∫—Å—Ç: {text}

–û—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π):"""
    
    try:
        response = requests.post(
            "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
            headers={"Authorization": f"Bearer {HF_TOKEN}"},
            json={
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 80,
                    "temperature": 0.7,
                    "do_sample": True,
                    "top_p": 0.9
                }
            },
            timeout=25
        )
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                result = data[0].get("generated_text", "").strip()
                if prompt in result:
                    result = result.split(prompt)[-1].strip()
                sentences = result.split('.')[:2]
                result = '.'.join(s.strip() for s in sentences if s.strip()) + '.'
                result = re.sub(r'\d+$', '', result).strip()
                return result[:200] if len(result) > 15 else text[:150]
    except Exception as e:
        safe_log(f"‚ö†Ô∏è HF –æ—à–∏–±–∫–∞: {str(e)[:40]}")
    
    return text[:150]

def download_image(url):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    if not url:
        return None
    
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            os.makedirs("data", exist_ok=True)
            filename = f"data/img_{int(time.time())}.jpg"
            with open(filename, 'wb') as f:
                f.write(response.content)
            return filename
    except:
        pass
    
    return None

def send_to_telegram(articles):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º 5-10 –º–∏–Ω—É—Ç"""
    if not articles:
        safe_log("‚ö†Ô∏è –ù–ï–¢ –ù–û–í–û–°–¢–ï–ô")
        return 0
    
    safe_log(f"üì§ –ü—É–±–ª–∏–∫—É—é {len(articles)} –ª—É—á—à–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º...\n")
    sent = 0
    
    for i, art in enumerate(articles):
        title = art["title"]
        summary = rewrite_with_hf(title, art["desc"])
        
        image_path = None
        if art["image"]:
            image_path = download_image(art["image"])
        
        msg = f"*{title}*\n\n{summary}"
        
        try:
            if image_path and os.path.exists(image_path):
                with open(image_path, 'rb') as photo:
                    files = {'photo': photo}
                    data = {
                        'chat_id': TG_CHAT_ID,
                        'caption': msg,
                        'parse_mode': 'Markdown'
                    }
                    requests.post(
                        f"https://api.telegram.org/bot{TG_TOKEN}/sendPhoto",
                        files=files,
                        data=data,
                        timeout=10
                    )
                try:
                    os.remove(image_path)
                except:
                    pass
            else:
                requests.post(
                    f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage",
                    json={
                        "chat_id": TG_CHAT_ID,
                        "text": msg,
                        "parse_mode": "Markdown"
                    },
                    timeout=10
                )
            
            safe_log(f"‚úì [{i+1}] {title[:40]}...")
            mark_sent(art["url"], art["title"], summary)
            sent += 1
            
            # –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏ 5-10 –º–∏–Ω—É—Ç (–Ω–æ –≤ GitHub Actions –¥–µ–ª–∞–µ–º –º–µ–Ω—å—à–µ)
            if i < len(articles) - 1:
                # –í —Ç–µ—Å—Ç–µ 10 —Å–µ–∫, –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ç—å –Ω–∞ 300-600
                time.sleep(10)
        
        except Exception as e:
            safe_log(f"‚úó [{i+1}] {str(e)[:50]}")
    
    return sent

def main():
    safe_log("üöÄ LENTA ‚Üí TELEGRAM (SMART RANKING)")
    safe_log(f"‚è∞ –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å...\n")
    
    if not all([HF_TOKEN, TG_TOKEN, TG_CHAT_ID]):
        safe_log("‚ùå –û–®–ò–ë–ö–ê: –Ω–µ—Ç —Å–µ–∫—Ä–µ—Ç–æ–≤!")
        return
    
    init_db()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
    articles = fetch_lenta_last_hour()
    
    if not articles:
        safe_log("‚ÑπÔ∏è –ù–ï–¢ –ù–û–í–û–°–¢–ï–ô –ó–ê –ü–û–°–õ–ï–î–ù–ò–ô –ß–ê–°")
        return
    
    # –ò–ò –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø 1-5
    top_articles = rank_articles_with_ai(articles)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
    sent = send_to_telegram(top_articles)
    safe_log(f"\n‚ú® –ì–û–¢–û–í–û! –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {sent}/{len(top_articles)}")

if __name__ == "__main__":
    main()
